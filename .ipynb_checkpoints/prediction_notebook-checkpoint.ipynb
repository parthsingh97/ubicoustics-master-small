{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "1 / 2: Checking Microphones... \n",
      "=====\n",
      "Using mic: # 0 - Microsoft Sound Mapper - Input\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from vggish_input import waveform_to_examples, wavfile_to_examples\n",
    "import ubicoustics\n",
    "import pyaudio\n",
    "from pathlib import Path\n",
    "import time\n",
    "import argparse\n",
    "import wget\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Variables\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = RATE\n",
    "MICROPHONES_DESCRIPTION = []\n",
    "FPS = 60.0\n",
    "\n",
    "###########################\n",
    "# Checl Microphone\n",
    "###########################\n",
    "print(\"=====\")\n",
    "print(\"1 / 2: Checking Microphones... \")\n",
    "print(\"=====\")\n",
    "\n",
    "import microphones\n",
    "desc, mics, indices = microphones.list_microphones()\n",
    "if (len(mics) == 0):\n",
    "    print(\"Error: No microphone found.\")\n",
    "    exit()\n",
    "\n",
    "#############\n",
    "# Read Command Line Args\n",
    "#############\n",
    "MICROPHONE_INDEX = indices[0]\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-m\", \"--mic\", help=\"Select which microphone / input device to use\")\n",
    "# args = parser.parse_args()\n",
    "# try:\n",
    "#     if args.mic:\n",
    "#         MICROPHONE_INDEX = int(args.mic)\n",
    "#         print(\"User selected mic: %d\" % MICROPHONE_INDEX)\n",
    "#     else:\n",
    "#         mic_in = input(\"Select microphone [%d]: \" % MICROPHONE_INDEX).strip()\n",
    "#         if (mic_in!=''):\n",
    "#             MICROPHONE_INDEX = int(mic_in)\n",
    "# except:\n",
    "#     print(\"Invalid microphone\")\n",
    "#     exit()\n",
    "\n",
    "# Find description that matches the mic index\n",
    "mic_desc = \"\"\n",
    "for k in range(len(indices)):\n",
    "    i = indices[k]\n",
    "    if (i==MICROPHONE_INDEX):\n",
    "        mic_desc = mics[k]\n",
    "print(\"Using mic: %s\" % mic_desc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "2 / 2: Checking model... \n",
      "=====\n",
      "Using deep learning model: models/example_model.hdf5\n",
      "--label\n",
      "{0: 'dog-bark', 1: 'drill', 2: 'hazard-alarm', 3: 'phone-ring', 4: 'speech', 5: 'vacuum', 6: 'baby-cry', 7: 'chopping', 8: 'cough', 9: 'door', 10: 'water-running', 11: 'knock', 12: 'microwave', 13: 'shaver', 14: 'toothbrush', 15: 'blender', 16: 'dishwasher', 17: 'doorbell', 18: 'flush', 19: 'hair-dryer', 20: 'laugh', 21: 'snore', 22: 'typing', 23: 'hammer', 24: 'car-horn', 25: 'engine', 26: 'saw', 27: 'cat-meow', 28: 'alarm-clock', 29: 'cooking'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\envs\\ubicoustics\\lib\\site-packages\\keras\\models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# Download model, if it doesn't exist\n",
    "###########################\n",
    "MODEL_URL = \"https://www.dropbox.com/s/cq1d7uqg0l28211/example_model.hdf5?dl=1\"\n",
    "MODEL_PATH = \"models/example_model.hdf5\"\n",
    "print(\"=====\")\n",
    "print(\"2 / 2: Checking model... \")\n",
    "print(\"=====\")\n",
    "model_filename = \"models/example_model.hdf5\"\n",
    "ubicoustics_model = Path(model_filename)\n",
    "if (not ubicoustics_model.is_file()):\n",
    "    print(\"Downloading example_model.hdf5 [867MB]: \")\n",
    "    wget.download(MODEL_URL,MODEL_PATH)\n",
    "\n",
    "##############################\n",
    "# Load Deep Learning Model\n",
    "##############################\n",
    "print(\"Using deep learning model: %s\" % (model_filename))\n",
    "model = load_model(model_filename)\n",
    "graph = tf.get_default_graph()\n",
    "context = ubicoustics.everything\n",
    "\n",
    "label = dict()\n",
    "for k in range(len(context)):\n",
    "    label[k] = context[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Setup Audio Callback\n",
    "##############################\n",
    "def audio_samples(in_data, frame_count, time_info, status_flags):\n",
    "    global graph\n",
    "    np_wav = np.fromstring(in_data, dtype=np.int16) / 32768.0 # Convert to [-1.0, +1.0]\n",
    "    x = waveform_to_examples(np_wav, RATE)\n",
    "    predictions = []\n",
    "    with graph.as_default():\n",
    "        if x.shape[0] != 0:\n",
    "            x = x.reshape(len(x), 96, 64, 1)\n",
    "            pred = model.predict(x)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        for prediction in predictions:\n",
    "            m = np.argmax(prediction[0])\n",
    "            if (m < len(label)):\n",
    "                p = label[m]\n",
    "                print(\"Prediction: %s (%0.2f)\" % (ubicoustics.to_human_labels[label[m]], prediction[0,m]))\n",
    "                n_items = prediction.shape[1]\n",
    "            else:\n",
    "                print(\"KeyError: %s\" % m)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "##############################\n",
    "# Prediction Function\n",
    "##############################\n",
    "def predict_wav(in_data, sample_rate=RATE):\n",
    "    global graph\n",
    "    \n",
    "#     np_wav = np.fromstring(in_data, dtype=np.int16) / 32768.0 # Convert to [-1.0, +1.0]\n",
    "#     x = waveform_to_examples(np_wav, sample_rate)\n",
    "    \n",
    "    assert in_data.dtype == np.int16, 'Bad sample type: %r' % in_data.dtype\n",
    "    np_wav = in_data / 32768.0  # Convert to [-1.0, +1.0]\n",
    "    x = waveform_to_examples(np_wav, sample_rate)\n",
    "    \n",
    "    predictions = []\n",
    "    output_list = []\n",
    "    with graph.as_default():\n",
    "\n",
    "        x = x.reshape(len(x), 96, 64, 1)\n",
    "        predictions = model.predict(x)\n",
    "\n",
    "        for k in range(len(predictions)):\n",
    "            prediction = predictions[k]\n",
    "            m = np.argmax(prediction)\n",
    "#             print(\"Prediction: %s (%0.2f)\" % (ubicoustics.to_human_labels[label[m]], prediction[m]))\n",
    "            output_list.append([ubicoustics.to_human_labels[label[m]], prediction[m]])\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\envs\\ubicoustics\\lib\\site-packages\\ipykernel_launcher.py:4: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Coughing', 1.0], ['Coughing', 0.9999722], ['Coughing', 0.9982481], ['Coughing', 0.9999887], ['Coughing', 0.99977094], ['Toilet Flushing', 1.0], ['Toilet Flushing', 1.0], ['Toilet Flushing', 1.0], ['Water Running', 0.99865097], ['Water Running', 0.9999087], ['Water Running', 0.99999833], ['Water Running', 0.9994715], ['Water Running', 0.99999034], ['Water Running', 0.9999994], ['Water Running', 0.9999937], ['Water Running', 0.9999968], ['Knocking', 0.99953187], ['Knocking', 0.98939604], ['Knocking', 0.9062936]]\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Prediction Function Usage\n",
    "##############################\n",
    "sr, wav_data = wavfile.read('example.wav')\n",
    "out = predict_wav(wav_data, sr)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
